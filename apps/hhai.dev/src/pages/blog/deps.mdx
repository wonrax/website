---
layout: "@/layouts/BlogPostLayout.astro"
title: "Dependencies, reproducibility and trust"
description: ""
published: '17 May 2025'
tags:
  - dependency
  - reproducibility
  - nix
  - rust
isDraft: true
---

Recently [a post](https://vincents.dev/blog/rust-dependencies-scare-me/) blew
up on Hacker News and many more places about Rust dependency hell. The post
just shallowly rants about how many dependencies needed for a simple Rust
project without proposing a solution, so there's not much to say about it.
However it did get me thinking about dependencies in general and how they
relate to reproducibility and trust, and how can we make them better without
giving up on the convenience they provide.

[LetsBeRealAboutDependencies](
https://wiki.alopex.li/LetsBeRealAboutDependencies) argues that package manager
and statically linked binaries are improvements upon the old way of doing
things--dynamic linking and shared libraries. However they're aware of the
tradeoffs that come with it. They also do not offer solutions to the problems
they raise, but rather just point them out.

> This is just a modern problem in all software development, regardless of language. We are doing more complex things, we have a much bigger library of existing code to draw from and there are many reasons to use it. Ultimately a dependency is untrusted code, and there's a long road to go in hardening entire systems to make running arbitrary dependencies safe (if its even possible). https://news.ycombinator.com/item?id=43941131

> It's a tradeoff. Those languages also have a very difficult time evolving anything in that standard library because the entire ecosystem relies on it and expects non-breaking changes. I think Rust gets sort of best of both worlds because dependencies are so easy to install it's almost as good as native, but there's a diversity of options and design choices, easy evolution and winners naturally emerge - these become as high quality as a stdlib component because they attract people/money to work on them but with more flexibility to change or be replaced https://news.ycombinator.com/user?id=zaptheimpaler

Just complaining without understanding the problem is harmful in my opinion
(people are scared of things they don't understand), and I think it's important
to understand the tradeoffs so that we can make better decisions and set up
guardrails to protect ourselves from the problems that come with them. It also
shows the ignorance of the works people have done to make the ecosystem better...

## Dependencies

When I use the word dependency, I don't just mean components that the software
imports, but also the abstractions that the software uses, whether it's a high
level programming language, a library, a framework or a package manager.


[LetsBeRealAboutDependencies](
https://wiki.alopex.li/LetsBeRealAboutDependencies) argues that package manager
and statically linked binaries are improvements upon the old way of doing
things--dynamic linking and shared libraries. However they're aware of the
tradeoffs that come with it. They also do not offer solutions to the problems
they raise, but rather just point them out.

> Because most dependencies are either manually installed by the user, or are dynamic libraries that are provided and audited by the distro maintainers. The dependencies are there, they're just harder to see https://news.ycombinator.com/item?id=43941299

Unfortunately, this post does not offer any solutions either, but rather argues
that package managers are fine, but we need to be aware of the tradeoffs they
bring. And shows what are the ways to address these problems.

Dependencies are not inherent, your project does not depend on some packages
does not mean you don't have dependencies. Your compiler may depend on some
runtime or build time dependencies,...

- Running the “Reflections on Trusting Trust” Compiler:
  >  The programming environments for languages like Go, NPM, and Rust make it
  >  trivial to download and run source code published by strangers on the
  >  internet, and again almost no one is checking the code, until there is a
  >  problem. No one needs Ken’s backdoor: there are far easier ways to mount a
  >  supply chain attack.
  >
  >  On the other hand, given all our reckless behavior, there are far fewer
  >  problems than you would expect. Quite the opposite: we trust computers
  >  with nearly every aspect of our lives, and for the most part nothing bad
  >  happens. Something about our security posture must be better than it
  >  seems. Even so, it might be nicer to live in a world where the only
  >  possible attacks required the sophistication of approaches like Ken’s
  >  (like in this excellent science fiction story).

- Minimize deps, don't use package managers at all, vendor your dependencies
  (JonBlow https://x.com/Jonathan_Blow/status/1923414922484232404)

  -
    > This means, for example: If you are shipping on iOS, you only reluctantly
    > use any functions iOS gives you, because when you use them, Tim Apple
    > will come along and break your program next year for arbitrary pointless
    > reasons, because Tim Apple does not respect you or anyone you know.

    Why would you depend on iOS libraries if you don't have to unless for some
    platform specific features? This seems like common sense. The same reason
    can be used to advocate for cross platform framework like Qt or Electron,
    but that wouldn't make them "good softwares" (in JonBlow term) as they are
    not as native as possible. Is JonBlow contradicting himself here?

  -
    > I shipped a binary for this game Braid in 2009 that you can still
    > download and play on Steam 16 years later. If you are pretty young (like
    > 35), you can run binaries on Windows that were compiled before you were
    > even born, which is amazing given how hard they have been trying to f up
    > Windows lately.

    That's because Windows really commits to backwards compatibility. So his
    argument is rather about platform decision rather than software complexity.
    Once that contract is broken, there's no guarantee that your software will
    run on the next version of Windows whether your software or game engine
    depends too little or too much on the winapi. One way to resolve this is
    you don't assume anything at all! (*start hinting about Nix in the next
    part*).

  - This is a good idea, but it doesn't scale well. You end up with a lot of
  code duplication and it's hard to keep track of what you have and what you
  don't have. It's also hard to update dependencies when you need to.
  - When you need to audit your dependencies, it's exponentially harder since
  every package has their own implementation of X. Whereas if you use a package
  manager, multiple packages can share the same implementation of X.
- On `Preventing the Collapse of Civilization` by Jonathan Blow
  - Instead of improving upon what we have, JonBlow suggests that we go back to
  the stone age and do everything ourselves. That is pretty idealistic and full
  of elitism. Just because he's a cracked programmer who doesn't have a life
  doesn't mean we all have to be like him.
    > With such a grandiose title, before I first watched I thought it must be
    > satire. Turns out, it is food for the credulous. I believe Jonathan Blow
    > is less "seriously worried about software quality/complexity" than he is
    > about marketing himself as the "last great hope".

    > He's missed the biggest part of all of this. It's never been about software. It's about humans being able to accomplish human things.
    >
    > ...
    >
    > He speaks like an artist of so many ages that was proud to be part of a small enclave of success. Surrounded by people who looked like him, had access to education and mentoring like him, and only open the doors for people like him.
    > Thankfully, that's just not how software works any more.

  - JonBlow is full of shit. His rants are nothing but peak elitism. He is the
  example of being in a specific domain and speaking out fallaciously of
  others. His being against abstraction and software safety is because he
  primarily works on games, where performance is crucial but the cost of
  incorrectness is approximately zero. Software complexity evolves naturally
  along with human accomplishments.
  - JonBlow is right to point out software inefficiencies, but his proposed
  solution makes no sense and toxic and harmful.

- https://x.com/cmuratori/status/1426299131270615040

  -
    > [3/*] With just one tool, the build has an over 95% chance of working after
    > five year. With ten tools, it has only a 60% chance! And that's with every
    > tool having a _99%_ chance of remaining working (meaning no breaking
    > changes to the tool that affect the build in question).

    Casey Muratori is right in some senses. But I think that's a reasonable
    cost of keeping the software up to date, and small price you have to pay
    for not implementing the dependencies yourself (although *very small*
    compared to actually implementing them). If you want to simply archive your
    software, there's countless way to do it. *(start hinting about Nix in the
    next part)*.

> With such a grandiose title, before I first watched I thought it must be satire. Turns out, it is food for the credulous. I believe Jonathan Blow is less "seriously worried about software quality/complexity" than he is about marketing himself as the "last great hope". At least Blow's software has found success within its domain. However, I fear Blow's problem is the problem of all intellectuals: “An intellectual is a person knowledgeable in one field who speaks out only in others.” Blow has plenty of opinions about software outside his domain, but IMHO very little curiosity about why his domain may be different than your own. https://news.ycombinator.com/item?id=43943607

- A mix of trust and verify (you can't verify everything), reduce blast radius
  and attack surface

- The case against https://www.youtube.com/watch?v=ZSRHeXYDLko
  - Abstraction enables less error prone programming, and allows parallelization
  of computing safely (rust fearless concurrency).


> "Dennis Richie created the C language. C is a very nice high level language
> with many of the modern programming constructs in it. The thing that is very
> important about it is that it lets you avoid the details of the machine when
> you want to, but when you need to and sometimes when you're writing an
> operating system you really do need to, you can get at the details of the
> machine and control everything. But you're not forced to do that, and that's
> important because that means you can write operating systems in this language
> and still have something that can be portable to other machines.
> https://www.youtube.com/watch?v=tc4ROCJYbm0

## Reproducibility

- Nix
  - Nix is not hard, nix exposes the complexity of the build and runtime
  complexity
  - Nix fixes the questions I have about software compliling and running on
  OSes. Why do you have to install random packages to build something or run
  some binary? And it's undocumented more often than not.

- > Rust's primary sin here is that it makes dependency usage transparent to the end-user. Nobody wants to think about how many libraries they depend upon and how many faceless people it takes to maintain those libraries, so they're uncomfortable when Rust shows you. This isn't a Rust problem, it's a software complexity problem. https://news.ycombinator.com/item?id=43946324

- An argument is to put as much things into the stdlib as possible
  - To reduce the number of dependencies, but this is not a good idea since
    it makes the stdlib more complex and harder to maintain (forever).

- Maybe also a part to compare docker (OCI container) and nix and how to compose them?

- Unfortunately Nix only works on Linux and MacOS, and it's not perfect either,
but I know someone on X who is building the next build system that will be
cross platform and work on all 3 major OSes, that claims to fix all Nix's
shortcomings. I don't know if that's true, but I think it's worth a believe.
https://github.com/cull-os/carcass

## Trust
We have to trust our dependencies to some extent. Society is built on trust,
and we can't live in a world where we don't trust anything. We trust the
compiler to not have a backdoor, otherwise we'd have to bootstrap our own
compiler. And how do we know that the bootstrapping compiler is also not
compromised? Just like [basic beliefs](https://iep.utm.edu/epi-just), we have
to trust some things without proof otherwise we'll fall into a vicious cycle of
infinite regress or total skepticism.

Depends on the seriousness of what you're building, the level of trust can be
different. Whether you need to assess the trustworthiness by number of GitHub
stars, number of dependents or downloads, trusting certified 3rd party audits
or or audit the code yourself.

- Level of assurance: https://slsa.dev/spec/v1.1/levels
  - Establish trust in a small number of platforms and systems—such as change management, build, and packaging platforms—and then automatically verify the many artifacts produced by those platforms.
  - Trusted computing bases are unavoidable—there’s no choice but to trust some platforms. Hardening and verifying platforms is difficult and expensive manual work, and each trusted platform expands the attack surface of the supply chain. Verifying that an artifact is produced by a trusted platform, though, is easy to automate.



\## TODO reproducibility

## How do we make it better?
For rust and cargo, but might apply to other languages as well:
- cargo-vendor: to not depend on centralized package registries.
- cargo-deny: to ban packages in lockfile that you don't trust.
- cargo-vet: to audit your dependencies
- cargo-crev: distributed code review

Now if we take a step back further, if we can't fully trust the program, can we
contain the damage? Deno has permission based sandboxing.

- Maybe zero trust is useful here? If the program of Ken Thompson can allow
  login from a backdoor, then could isolating the program behind firewall and
  limiting the access to the network and filesystem help?

> trust is typically managed at the repository-level. An organization trusts an SCM for their first-party code, and a series of artifact managers (language, container) for their third-party code. Stricter companies may require all artifacts to be mirrored into a fully-trusted first-party repository. In these scenarios, trust moves internal but remains at the repository level.
> https://dlorenc.medium.com/zero-trust-supply-chain-security-e3fb8b6973b8


\## TODO fix the adding comments complexity analysis
\## TODO Include X profile in about page

As Rust's philosophy is to embrace everyone to build reliable software:
> As much as I disagree with the speaker, I love how much of this is the result of experience and deep thought on a subject.
> 
> That said, I'd love to see him create a company that puts in the work to replace all of these mediocre systems and offers this 'something better' that everyone will want to adopt. Where's his will to make such a difference? He's not going to do and this is reflected in his response at 1:01:08 "Yeah...I don't know man." 
> 
> He's missed the biggest part of all of this. It's never been about software. It's about humans being able to accomplish human things.
> 
> 
> He recommends the equivalent of requiring that every person who wants to write a book that passes on valuable knowledge needing to know how make paper. We would be left with a civilization of paper makers and no one sharing knowledge that empowers more and more people to go out and do amazing things.
> 
> He speaks like an artist of so many ages that was proud to be part of a small enclave of success. Surrounded by people who looked like him, had access to education and mentoring like him, and only open the doors for people like him.
> 
> Thankfully, that's just not how software works any more.
> https://www.youtube.com/watch?v=ZSRHeXYDLko&lc=UgwEUc46IkIfqsjwNPN4AaABAg


